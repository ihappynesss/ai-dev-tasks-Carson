/**
 * Integration Tests: Error Recovery and Retry Mechanisms
 * Task 14.12: Test error recovery and retry mechanisms in realistic scenarios
 *
 * Tests:
 * - Retry logic with exponential backoff
 * - Circuit breaker patterns
 * - Fallback mechanisms
 * - Error classification and handling
 * - Redis queue for failed operations
 */

const { freshdeskMock } = require('./helpers/freshdesk-mock');
const { maintenanceTicket, createWebhookRequest } = require('./fixtures/webhook-payloads');

describe('Error Recovery Integration Tests (Task 14.12)', () => {
  beforeEach(() => {
    freshdeskMock.reset();
  });

  afterEach(() => {
    freshdeskMock.reset();
  });

  describe('Retry Logic with Exponential Backoff (Task 11.1, 6.7)', () => {
    test('should retry 3 times with 5 second delays', async () => {
      const ticketId = maintenanceTicket.ticket.id;
      const retryConfig = {
        maxTries: 3,
        waitBetweenTries: 5000,
        exponential: false
      };

      let attempts = 0;
      const attemptTimes = [];

      while (attempts < retryConfig.maxTries) {
        attempts++;
        attemptTimes.push(Date.now());

        try {
          // Simulate API call that fails first 2 times
          if (attempts < 3) {
            throw new Error('Connection timeout');
          }
          // Success on 3rd attempt
          break;
        } catch (error) {
          if (attempts < retryConfig.maxTries) {
            // In real test, would actually wait
            // await new Promise(resolve => setTimeout(resolve, retryConfig.waitBetweenTries));
          }
        }
      }

      expect(attempts).toBe(3);
      expect(attemptTimes.length).toBe(3);
    });

    test('should use exponential backoff for rate limits', async () => {
      let retryDelay = 5000; // Start at 5 seconds
      const delays = [];

      for (let i = 0; i < 3; i++) {
        delays.push(retryDelay);
        retryDelay = Math.min(retryDelay * 2, 60000); // Double, max 60s
      }

      expect(delays[0]).toBe(5000);   // 5s
      expect(delays[1]).toBe(10000);  // 10s
      expect(delays[2]).toBe(20000);  // 20s
    });

    test('should respect Retry-After header from API', () => {
      const apiResponse = {
        statusCode: 429,
        headers: {
          'Retry-After': '120'
        }
      };

      const retryAfter = parseInt(apiResponse.headers['Retry-After']) || 5000;
      const maxDelay = 60000;
      const actualDelay = Math.min(retryAfter * 1000, maxDelay);

      expect(actualDelay).toBe(60000); // Capped at 60s
    });

    test('should handle successful retry after temporary failure', async () => {
      const ticketId = maintenanceTicket.ticket.id;

      // Mock: fails twice, succeeds on third attempt
      freshdeskMock.mockRetryScenario(ticketId, 2);

      let success = false;
      let attempts = 0;

      while (attempts < 3 && !success) {
        attempts++;
        try {
          if (attempts === 3) {
            success = true;
          } else {
            throw new Error('Temporary failure');
          }
        } catch (error) {
          if (attempts < 3) {
            // Wait and retry
            await new Promise(resolve => setTimeout(resolve, 10));
          }
        }
      }

      expect(success).toBe(true);
      expect(attempts).toBe(3);
    });
  });

  describe('Circuit Breaker Pattern (Task 11.8)', () => {
    class CircuitBreaker {
      constructor(threshold = 3, timeout = 30000) {
        this.threshold = threshold;
        this.timeout = timeout;
        this.failures = 0;
        this.lastFailureTime = null;
        this.state = 'closed'; // closed, open, half-open
      }

      async call(fn) {
        if (this.state === 'open') {
          const elapsed = Date.now() - this.lastFailureTime;
          if (elapsed < this.timeout) {
            throw new Error('Circuit breaker is OPEN');
          }
          // Try half-open state
          this.state = 'half-open';
        }

        try {
          const result = await fn();
          this.onSuccess();
          return result;
        } catch (error) {
          this.onFailure();
          throw error;
        }
      }

      onSuccess() {
        this.failures = 0;
        this.state = 'closed';
      }

      onFailure() {
        this.failures++;
        this.lastFailureTime = Date.now();

        if (this.failures >= this.threshold) {
          this.state = 'open';
        }
      }

      getState() {
        return this.state;
      }
    }

    test('should open circuit after threshold failures', async () => {
      const breaker = new CircuitBreaker(3, 30000);

      // Fail 3 times
      for (let i = 0; i < 3; i++) {
        try {
          await breaker.call(async () => {
            throw new Error('Service unavailable');
          });
        } catch (error) {
          // Expected
        }
      }

      expect(breaker.getState()).toBe('open');
    });

    test('should block requests when circuit is open', async () => {
      const breaker = new CircuitBreaker(3, 30000);

      // Open the circuit
      for (let i = 0; i < 3; i++) {
        try {
          await breaker.call(async () => {
            throw new Error('Fail');
          });
        } catch (error) {
          // Expected
        }
      }

      // Circuit is now open - next call should be blocked
      await expect(
        breaker.call(async () => 'success')
      ).rejects.toThrow('Circuit breaker is OPEN');
    });

    test('should reset after successful call in half-open state', async () => {
      const breaker = new CircuitBreaker(3, 100); // Short timeout for test

      // Open the circuit
      for (let i = 0; i < 3; i++) {
        try {
          await breaker.call(async () => {
            throw new Error('Fail');
          });
        } catch (error) {
          // Expected
        }
      }

      expect(breaker.getState()).toBe('open');

      // Wait for timeout
      await new Promise(resolve => setTimeout(resolve, 150));

      // Try again - should go to half-open
      const result = await breaker.call(async () => 'success');

      expect(result).toBe('success');
      expect(breaker.getState()).toBe('closed');
    });
  });

  describe('Fallback Mechanisms (Task 11.9-11.11)', () => {
    test('should fallback from vector search to keyword search', async () => {
      const searchQuery = 'roof leak maintenance';
      let results = null;

      // Try vector search first
      try {
        throw new Error('Vector database timeout');
      } catch (error) {
        // Fallback to keyword search
        results = {
          method: 'keyword',
          query: searchQuery,
          results: [
            { id: 1, title: 'Roof Leak Resolution', score: 0.75 }
          ]
        };
      }

      expect(results.method).toBe('keyword');
      expect(results.results.length).toBeGreaterThan(0);
    });

    test('should fallback through AI provider hierarchy', async () => {
      const fallbackChain = ['claude', 'gpt-4o', 'gpt-4o-mini'];
      let provider = null;
      let attempts = 0;

      for (const providerName of fallbackChain) {
        attempts++;
        try {
          if (providerName === 'claude' || providerName === 'gpt-4o') {
            throw new Error(`${providerName} unavailable`);
          }
          provider = providerName;
          break;
        } catch (error) {
          // Continue to next provider
        }
      }

      expect(provider).toBe('gpt-4o-mini');
      expect(attempts).toBe(3);
    });

    test('should queue webhook to Redis when Freshdesk unavailable', async () => {
      const ticketId = maintenanceTicket.ticket.id;

      // Mock Freshdesk unavailable
      freshdeskMock.mockPostReply(ticketId, {
        shouldFail: true,
        statusCode: 503
      });

      try {
        // Attempt to post reply
        throw new Error('Freshdesk API unavailable');
      } catch (error) {
        // Queue to Redis for retry
        const queuedOperation = {
          ticketId: ticketId,
          operation: 'post_reply',
          payload: {
            body: 'Response to be sent',
            from_email: 'support@example.com'
          },
          timestamp: new Date().toISOString(),
          ttl: 604800, // 7 days
          retryCount: 0
        };

        expect(queuedOperation.operation).toBe('post_reply');
        expect(queuedOperation.ttl).toBe(604800);
        expect(queuedOperation.retryCount).toBe(0);
      }
    });
  });

  describe('Error Classification (Task 11.7)', () => {
    function classifyError(error) {
      const classification = {
        type: 'unknown',
        severity: 'medium',
        retryable: false,
        action: 'log'
      };

      // Transient errors - retry
      if (error.code === 'ETIMEDOUT' || error.code === 'ECONNRESET') {
        classification.type = 'transient';
        classification.severity = 'low';
        classification.retryable = true;
        classification.action = 'retry';
      } else if (error.statusCode === 503 || error.statusCode === 429) {
        classification.type = 'transient';
        classification.severity = 'low';
        classification.retryable = true;
        classification.action = 'retry_with_backoff';
      }
      // Systematic errors - fix configuration
      else if (error.statusCode === 401 || error.statusCode === 403) {
        classification.type = 'systematic';
        classification.severity = 'high';
        classification.retryable = false;
        classification.action = 'alert_admin';
      } else if (error.statusCode === 404) {
        classification.type = 'systematic';
        classification.severity = 'medium';
        classification.retryable = false;
        classification.action = 'check_configuration';
      }
      // Critical errors - immediate attention
      else if (error.statusCode === 500 || error.code === 'DATABASE_ERROR') {
        classification.type = 'critical';
        classification.severity = 'critical';
        classification.retryable = false;
        classification.action = 'notify_slack_and_escalate';
      }

      return classification;
    }

    test('should classify timeout as transient and retryable', () => {
      const error = { code: 'ETIMEDOUT' };
      const classification = classifyError(error);

      expect(classification.type).toBe('transient');
      expect(classification.retryable).toBe(true);
      expect(classification.action).toBe('retry');
    });

    test('should classify 429 rate limit as transient', () => {
      const error = { statusCode: 429 };
      const classification = classifyError(error);

      expect(classification.type).toBe('transient');
      expect(classification.action).toBe('retry_with_backoff');
    });

    test('should classify 401 as systematic and non-retryable', () => {
      const error = { statusCode: 401 };
      const classification = classifyError(error);

      expect(classification.type).toBe('systematic');
      expect(classification.retryable).toBe(false);
      expect(classification.action).toBe('alert_admin');
    });

    test('should classify 500 as critical', () => {
      const error = { statusCode: 500 };
      const classification = classifyError(error);

      expect(classification.type).toBe('critical');
      expect(classification.severity).toBe('critical');
      expect(classification.action).toBe('notify_slack_and_escalate');
    });

    test('should classify database errors as critical', () => {
      const error = { code: 'DATABASE_ERROR', message: 'Connection lost' };
      const classification = classifyError(error);

      expect(classification.type).toBe('critical');
    });
  });

  describe('Error Logging and Notification (Task 11.4, 11.5)', () => {
    test('should create comprehensive error log entry', () => {
      const ticket = maintenanceTicket.ticket;
      const error = new Error('API call failed');
      error.stack = 'Error: API call failed\n    at processTicket...';

      const errorLog = {
        id: 'error-' + Date.now(),
        ticketId: ticket.id,
        errorType: 'systematic',
        errorMessage: error.message,
        errorStack: error.stack,
        errorCode: 404,
        payload: {
          ticketId: ticket.id,
          operation: 'get_ticket',
          url: `/api/v2/tickets/${ticket.id}`
        },
        timestamp: new Date().toISOString(),
        workflowId: 'main-ticket-processor',
        nodeId: 'get-ticket-details',
        context: {
          attemptNumber: 2,
          totalAttempts: 3,
          previousErrors: []
        }
      };

      expect(errorLog.ticketId).toBe(ticket.id);
      expect(errorLog.errorType).toBe('systematic');
      expect(errorLog.payload).toBeDefined();
      expect(errorLog.context.attemptNumber).toBe(2);
    });

    test('should send Slack notification for critical errors', async () => {
      const criticalError = {
        type: 'critical',
        message: 'Database connection pool exhausted',
        ticketId: 1001,
        timestamp: new Date().toISOString()
      };

      const slackPayload = {
        channel: '#strata-alerts',
        username: 'n8n Alert Bot',
        icon_emoji: ':rotating_light:',
        attachments: [
          {
            color: 'danger',
            title: 'ðŸš¨ Critical Error Alert',
            text: criticalError.message,
            fields: [
              { title: 'Ticket ID', value: criticalError.ticketId, short: true },
              { title: 'Error Type', value: criticalError.type, short: true },
              { title: 'Timestamp', value: criticalError.timestamp, short: false }
            ],
            footer: 'NSW Strata Automation',
            ts: Math.floor(Date.now() / 1000)
          }
        ]
      };

      expect(slackPayload.attachments[0].color).toBe('danger');
      expect(slackPayload.attachments[0].title).toContain('Critical Error');
      expect(slackPayload.attachments[0].fields.length).toBe(3);
    });

    test('should not spam Slack for transient errors', () => {
      const errors = [
        { type: 'transient', count: 5 },
        { type: 'systematic', count: 2 },
        { type: 'critical', count: 1 }
      ];

      const shouldNotify = errors.filter(e =>
        e.type === 'critical' || (e.type === 'systematic' && e.count > 3)
      );

      expect(shouldNotify.length).toBe(1);
      expect(shouldNotify[0].type).toBe('critical');
    });
  });

  describe('Redis Queue for Failed Operations (Task 11.6)', () => {
    test('should store failed operation with 7-day TTL', () => {
      const failedOp = {
        id: 'op-' + Date.now(),
        ticketId: maintenanceTicket.ticket.id,
        operation: 'post_reply',
        payload: {
          body: 'Response text',
          from_email: 'support@example.com'
        },
        error: {
          message: 'Freshdesk API unavailable',
          code: 503
        },
        timestamp: new Date().toISOString(),
        ttl: 604800, // 7 days in seconds
        retryCount: 0,
        maxRetries: 5,
        nextRetry: new Date(Date.now() + 300000).toISOString() // 5 minutes
      };

      expect(failedOp.ttl).toBe(604800);
      expect(failedOp.retryCount).toBe(0);
      expect(failedOp.maxRetries).toBe(5);
    });

    test('should increment retry count on each attempt', () => {
      const operation = {
        retryCount: 0,
        maxRetries: 5
      };

      // Simulate 3 retry attempts
      for (let i = 0; i < 3; i++) {
        operation.retryCount++;
        operation.nextRetry = new Date(Date.now() + (300000 * Math.pow(2, i))).toISOString();
      }

      expect(operation.retryCount).toBe(3);
      expect(operation.retryCount).toBeLessThan(operation.maxRetries);
    });

    test('should abandon operation after max retries', () => {
      const operation = {
        retryCount: 5,
        maxRetries: 5
      };

      const shouldRetry = operation.retryCount < operation.maxRetries;
      expect(shouldRetry).toBe(false);

      if (!shouldRetry) {
        operation.status = 'abandoned';
        operation.abandonedAt = new Date().toISOString();
      }

      expect(operation.status).toBe('abandoned');
      expect(operation.abandonedAt).toBeDefined();
    });
  });

  describe('Manual Intervention Workflow (Task 11.12)', () => {
    test('should create manual intervention ticket for unrecoverable error', () => {
      const originalTicket = maintenanceTicket.ticket;
      const error = {
        type: 'critical',
        message: 'Unrecoverable database error',
        attempts: 3
      };

      const interventionTicket = {
        subject: `MANUAL INTERVENTION REQUIRED: Ticket ${originalTicket.id} failed processing`,
        description: `
          <h3>Original Ticket Details</h3>
          <p><strong>ID:</strong> ${originalTicket.id}</p>
          <p><strong>Subject:</strong> ${originalTicket.subject}</p>
          <p><strong>Requester:</strong> ${maintenanceTicket.requester.email}</p>

          <h3>Error Information</h3>
          <p><strong>Error Type:</strong> ${error.type}</p>
          <p><strong>Error Message:</strong> ${error.message}</p>
          <p><strong>Attempts:</strong> ${error.attempts}</p>

          <h3>Required Action</h3>
          <p>Manual processing required. Please review and handle this ticket manually.</p>
        `,
        priority: 4, // Urgent
        status: 2, // Open
        tags: ['manual-intervention', 'automation-failed', 'critical'],
        group_id: 'technical-team',
        custom_fields: {
          original_ticket_id: originalTicket.id,
          error_type: error.type,
          automation_status: 'failed'
        }
      };

      expect(interventionTicket.priority).toBe(4);
      expect(interventionTicket.tags).toContain('manual-intervention');
      expect(interventionTicket.custom_fields.original_ticket_id).toBe(originalTicket.id);
    });
  });

  describe('Error Pattern Detection (Task 11.14)', () => {
    test('should detect repeating error patterns', () => {
      const recentErrors = [
        { type: 'api_timeout', endpoint: '/tickets/1001', timestamp: Date.now() - 60000 },
        { type: 'api_timeout', endpoint: '/tickets/1002', timestamp: Date.now() - 45000 },
        { type: 'api_timeout', endpoint: '/tickets/1003', timestamp: Date.now() - 30000 },
        { type: 'api_timeout', endpoint: '/tickets/1004', timestamp: Date.now() - 15000 }
      ];

      // Group by type
      const errorCounts = {};
      recentErrors.forEach(e => {
        errorCounts[e.type] = (errorCounts[e.type] || 0) + 1;
      });

      const repeatingPattern = Object.entries(errorCounts).find(([type, count]) => count >= 3);

      expect(repeatingPattern).toBeDefined();
      expect(repeatingPattern[0]).toBe('api_timeout');
      expect(repeatingPattern[1]).toBe(4);
    });

    test('should detect cascading failures', () => {
      const errors = [
        { service: 'database', timestamp: Date.now() - 10000 },
        { service: 'cache', timestamp: Date.now() - 8000 },
        { service: 'api', timestamp: Date.now() - 5000 },
        { service: 'webhook', timestamp: Date.now() - 2000 }
      ];

      // Check if multiple services failed within 30 seconds
      const timeWindow = 30000;
      const oldestError = Math.min(...errors.map(e => e.timestamp));
      const newestError = Math.max(...errors.map(e => e.timestamp));

      const isCascading = (newestError - oldestError) < timeWindow && errors.length >= 3;

      expect(isCascading).toBe(true);
    });
  });
});
